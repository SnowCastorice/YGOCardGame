#!/usr/bin/env python3
"""
LOCH å¡å›¾æœ¬åœ°åŒ–ä¸‹è½½è„šæœ¬
ä» loch_image_map.json è¯»å–æ‰€æœ‰ metaId / altMetaIdï¼Œ
æ‰¹é‡ä¸‹è½½ _w200ï¼ˆå°å›¾ï¼‰å’Œ _w420ï¼ˆå¤§å›¾ï¼‰åˆ° data/ocg/images/loch/ ç›®å½•ã€‚

ç”¨æ³•ï¼š
  cd YGOCardGame
  python tools/download_loch_images.py
"""

import json
import os
import time
import urllib.request
import urllib.error

# é…ç½®
CDN_BASE = "https://s3.duellinksmeta.com/cards"
SIZES = ["_w200", "_w420"]
MAP_FILE = os.path.join(os.path.dirname(__file__), "..", "data", "ocg", "loch_image_map.json")
OUTPUT_DIR = os.path.join(os.path.dirname(__file__), "..", "data", "ocg", "images", "loch")

# é‡è¯•é…ç½®
MAX_RETRIES = 3
RETRY_DELAY = 2  # ç§’


def download_file(url, filepath):
    """ä¸‹è½½æ–‡ä»¶ï¼Œå¸¦é‡è¯•æœºåˆ¶"""
    for attempt in range(MAX_RETRIES):
        try:
            req = urllib.request.Request(url, headers={
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
            })
            with urllib.request.urlopen(req, timeout=30) as response:
                data = response.read()
                with open(filepath, "wb") as f:
                    f.write(data)
                return len(data)
        except (urllib.error.URLError, urllib.error.HTTPError, TimeoutError) as e:
            if attempt < MAX_RETRIES - 1:
                print(f"  âš  é‡è¯• ({attempt + 1}/{MAX_RETRIES}): {e}")
                time.sleep(RETRY_DELAY)
            else:
                print(f"  âœ— ä¸‹è½½å¤±è´¥: {url} -> {e}")
                return None
    return None


def main():
    # è¯»å–æ˜ å°„è¡¨
    with open(MAP_FILE, "r", encoding="utf-8") as f:
        data = json.load(f)

    cards = data.get("cards", {})

    # æ”¶é›†æ‰€æœ‰éœ€è¦ä¸‹è½½çš„ metaIdï¼ˆå»é‡ï¼‰
    meta_ids = set()
    for pw, info in cards.items():
        if info.get("metaId"):
            meta_ids.add(info["metaId"])
        # æ”¶é›† altMetaIdï¼ˆOF è¶…æ¡†å¡å›¾ï¼‰
        alt = info.get("altMetaId", {})
        for rarity, alt_id in alt.items():
            if alt_id:
                meta_ids.add(alt_id)

    print(f"ğŸ“¦ LOCH å¡å›¾æœ¬åœ°åŒ–ä¸‹è½½")
    print(f"   å¡ç‰‡æ€»æ•°: {len(cards)}")
    print(f"   å»é‡å metaId æ•°: {len(meta_ids)}")
    print(f"   æ¯ä¸ª metaId ä¸‹è½½ {len(SIZES)} ä¸ªå°ºå¯¸: {', '.join(SIZES)}")
    print(f"   æ€»å…±éœ€è¦ä¸‹è½½: {len(meta_ids) * len(SIZES)} ä¸ªæ–‡ä»¶")
    print(f"   è¾“å‡ºç›®å½•: {os.path.abspath(OUTPUT_DIR)}")
    print()

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    # ä¸‹è½½
    total = len(meta_ids) * len(SIZES)
    done = 0
    skipped = 0
    failed = 0
    total_bytes = 0

    for meta_id in sorted(meta_ids):
        for size in SIZES:
            done += 1
            filename = f"{meta_id}{size}.webp"
            filepath = os.path.join(OUTPUT_DIR, filename)

            # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ä¸”å¤§å° > 0ï¼Œè·³è¿‡
            if os.path.exists(filepath) and os.path.getsize(filepath) > 0:
                skipped += 1
                print(f"  [{done}/{total}] â­ å·²å­˜åœ¨: {filename}")
                continue

            url = f"{CDN_BASE}/{meta_id}{size}.webp"
            print(f"  [{done}/{total}] â¬‡ ä¸‹è½½: {filename} ...", end=" ", flush=True)

            file_size = download_file(url, filepath)
            if file_size is not None:
                total_bytes += file_size
                print(f"âœ“ ({file_size / 1024:.1f} KB)")
            else:
                failed += 1

            # è¯·æ±‚é—´éš”ï¼Œé¿å…è¢« CDN é™æµ
            time.sleep(.3)

    print()
    print(f"âœ… ä¸‹è½½å®Œæˆ!")
    print(f"   æˆåŠŸ: {done - skipped - failed}")
    print(f"   è·³è¿‡(å·²å­˜åœ¨): {skipped}")
    print(f"   å¤±è´¥: {failed}")
    print(f"   æ€»å¤§å°: {total_bytes / 1024 / 1024:.1f} MB")


if __name__ == "__main__":
    main()
